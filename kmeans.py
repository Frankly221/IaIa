import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples
import warnings
warnings.filterwarnings('ignore')

# 1. Cargar los datos transformados por PCA
print("=" * 70)
print("DETERMINACI√ìN DEL K √ìPTIMO PARA K-MEANS - SISTEMA DE ENTREGAS")
print("=" * 70)

# Cargar los datos PCA generados anteriormente
try:
    df_pca = pd.read_csv('entregas_pca_projection.csv')
    print(f"‚úÖ Datos PCA cargados exitosamente: {df_pca.shape}")
    print(f"Columnas disponibles: {list(df_pca.columns)}")
    
    # Usar todos los componentes principales
    X_pca = df_pca.copy()
    
    print(f"\nDatos para an√°lisis: {X_pca.shape}")
    print(f"Componentes principales: {list(X_pca.columns)}")
    
except FileNotFoundError:
    print("‚ùå Error: No se encuentra 'entregas_pca_projection.csv'")
    print("Ejecuta primero el script PCA_entregas.py para generar los datos transformados")
    exit()

# 2. An√°lisis del m√©todo del Codo (Elbow Method)
print(f"\n" + "=" * 70)
print("M√âTODO DEL CODO (ELBOW METHOD)")
print("=" * 70)

# Rango de clusters a probar
k_range = range(1, 11)
inertias = []
silhouette_scores = []

print("Calculando inercias y scores de silhouette...")
for k in k_range:
    print(f"Probando k={k}...", end=" ")
    
    # Entrenar K-means
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
    kmeans.fit(X_pca)
    
    # Guardar inercia
    inertias.append(kmeans.inertia_)
    
    # Calcular silhouette score (solo para k > 1)
    if k > 1:
        silhouette_avg = silhouette_score(X_pca, kmeans.labels_)
        silhouette_scores.append(silhouette_avg)
        print(f"Inercia: {kmeans.inertia_:.2f}, Silhouette: {silhouette_avg:.3f}")
    else:
        silhouette_scores.append(0)  # No hay silhouette para k=1
        print(f"Inercia: {kmeans.inertia_:.2f}")

# 3. Visualizaci√≥n del m√©todo del codo
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# Gr√°fico de inercias (m√©todo del codo)
ax1.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)
ax1.set_xlabel('N√∫mero de Clusters (k)', fontsize=11)
ax1.set_ylabel('Inercia (WCSS)', fontsize=11)
ax1.set_title('M√©todo del Codo - Determinaci√≥n de K √ìptimo\nSistema de Entregas Log√≠sticas', 
              fontsize=12, fontweight='bold')
ax1.grid(True, alpha=0.3)
ax1.set_xticks(k_range)

# A√±adir valores en los puntos
for i, (k, inercia) in enumerate(zip(k_range, inertias)):
    ax1.annotate(f'{inercia:.0f}', (k, inercia), textcoords="offset points", 
                xytext=(0,10), ha='center', fontsize=9)

# Calcular y mostrar la diferencia relativa (para identificar el codo)
diferencias = []
for i in range(1, len(inertias)):
    diff = (inertias[i-1] - inertias[i]) / inertias[i-1] * 100
    diferencias.append(diff)

# Gr√°fico de diferencias porcentuales
ax2.plot(k_range[1:], diferencias, 'ro-', linewidth=2, markersize=8)
ax2.set_xlabel('N√∫mero de Clusters (k)', fontsize=11)
ax2.set_ylabel('Reducci√≥n de Inercia (%)', fontsize=11)
ax2.set_title('Reducci√≥n Porcentual de Inercia\nSistema de Entregas Log√≠sticas', 
              fontsize=12, fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.set_xticks(k_range[1:])

for i, (k, diff) in enumerate(zip(k_range[1:], diferencias)):
    ax2.annotate(f'{diff:.1f}%', (k, diff), textcoords="offset points", 
                xytext=(0,10), ha='center', fontsize=9)

plt.tight_layout()
plt.show()

# 4. An√°lisis de Silhouette detallado
print(f"\n" + "=" * 70)
print("AN√ÅLISIS DE SILHOUETTE")
print("=" * 70)

# Probar un rango m√°s espec√≠fico para silhouette
k_silhouette_range = range(2, 8)
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.ravel()

silhouette_results = {}

for idx, k in enumerate(k_silhouette_range):
    print(f"\nAnalizando k={k}:")
    
    # Entrenar K-means
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
    cluster_labels = kmeans.fit_predict(X_pca)
    
    # Calcular silhouette score
    silhouette_avg = silhouette_score(X_pca, cluster_labels)
    sample_silhouette_values = silhouette_samples(X_pca, cluster_labels)
    
    # Guardar resultados
    silhouette_results[k] = {
        'avg_score': silhouette_avg,
        'sample_values': sample_silhouette_values,
        'cluster_labels': cluster_labels
    }
    
    print(f"  Score promedio de silhouette: {silhouette_avg:.3f}")
    
    # Crear gr√°fico de silhouette
    ax = axes[idx]
    y_lower = 10
    
    for i in range(k):
        # Valores de silhouette para cluster i
        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
        ith_cluster_silhouette_values.sort()
        
        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i
        
        color = plt.cm.nipy_spectral(float(i) / k)
        ax.fill_betweenx(np.arange(y_lower, y_upper),
                        0, ith_cluster_silhouette_values,
                        facecolor=color, edgecolor=color, alpha=0.7)
        
        # Etiquetar cluster
        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        y_lower = y_upper + 10
    
    ax.set_xlabel('Valores de Silhouette', fontsize=10)
    ax.set_ylabel('√çndice de Cluster', fontsize=10)
    ax.set_title(f'Silhouette k={k} (Score: {silhouette_avg:.3f})', 
                fontsize=11, fontweight='bold')
    
    # L√≠nea vertical para el score promedio
    ax.axvline(x=silhouette_avg, color="red", linestyle="--", 
               label=f'Score promedio: {silhouette_avg:.3f}')
    ax.legend(fontsize=9)
    
    # Informaci√≥n por cluster
    for i in range(k):
        cluster_silhouette = sample_silhouette_values[cluster_labels == i]
        print(f"    Cluster {i}: {len(cluster_silhouette)} entregas, "
              f"silhouette promedio: {cluster_silhouette.mean():.3f}")

plt.suptitle('An√°lisis de Silhouette por N√∫mero de Clusters\nSistema de Entregas Log√≠sticas', 
             fontsize=14, fontweight='bold', y=1.00)
plt.tight_layout()
plt.show()

# 5. Gr√°fico comparativo de Silhouette Scores
fig, ax = plt.subplots(1, 1, figsize=(12, 7))

metrics_k = list(silhouette_results.keys())
metrics_scores = [silhouette_results[k]['avg_score'] for k in metrics_k]

bars = ax.bar(metrics_k, metrics_scores, alpha=0.7, color='lightblue', edgecolor='navy')
ax.set_xlabel('N√∫mero de Clusters (k)', fontsize=11)
ax.set_ylabel('Silhouette Score', fontsize=11)
ax.set_title('Comparaci√≥n de Silhouette Scores por Valor de K\nSistema de Entregas Log√≠sticas', 
            fontsize=12, fontweight='bold')
ax.grid(True, alpha=0.3, axis='y')
ax.set_xticks(metrics_k)

# A√±adir valores sobre las barras
for bar, score in zip(bars, metrics_scores):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
             f'{score:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Resaltar el mejor k
best_idx = np.argmax(metrics_scores)
bars[best_idx].set_color('lightgreen')
bars[best_idx].set_edgecolor('darkgreen')
bars[best_idx].set_linewidth(2)

plt.tight_layout()
plt.show()

# 6. Resumen de resultados y recomendaciones
print(f"\n" + "=" * 70)
print("RESUMEN DE RESULTADOS Y RECOMENDACIONES")
print("=" * 70)

# An√°lisis del m√©todo del codo
print("\nüìä M√âTODO DEL CODO:")
max_diff_idx = np.argmax(diferencias)
codo_k = k_range[max_diff_idx + 1]
print(f"   Mayor reducci√≥n de inercia: k={codo_k} ({diferencias[max_diff_idx]:.1f}%)")

# Buscar el "codo" manualmente (donde la mejora se estabiliza)
print("   An√°lisis de reducci√≥n de inercia:")
for i, (k, diff) in enumerate(zip(k_range[1:], diferencias)):
    emoji = "üî•" if diff > 20 else "üìä" if diff > 10 else "üìâ"
    print(f"     {emoji} k={k}: {diff:.1f}% de reducci√≥n")

# An√°lisis de silhouette
print(f"\nüìà AN√ÅLISIS DE SILHOUETTE:")
best_k_silhouette = max(silhouette_results.keys(), 
                       key=lambda k: silhouette_results[k]['avg_score'])
best_silhouette_score = silhouette_results[best_k_silhouette]['avg_score']

print(f"   Mejor k seg√∫n silhouette: k={best_k_silhouette} "
      f"(score: {best_silhouette_score:.3f})")

print("   Ranking de k por score de silhouette:")
sorted_k = sorted(silhouette_results.keys(), 
                 key=lambda k: silhouette_results[k]['avg_score'], reverse=True)
for i, k in enumerate(sorted_k, 1):
    score = silhouette_results[k]['avg_score']
    medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else "  "
    print(f"     {medal} {i}. k={k}: {score:.3f}")

# Interpretaci√≥n de calidad del clustering
print(f"\nüìä INTERPRETACI√ìN DE CALIDAD:")
if best_silhouette_score > 0.5:
    calidad = "EXCELENTE ‚≠ê‚≠ê‚≠ê"
elif best_silhouette_score > 0.4:
    calidad = "BUENA ‚≠ê‚≠ê"
elif best_silhouette_score > 0.3:
    calidad = "ACEPTABLE ‚≠ê"
else:
    calidad = "D√âBIL ‚ö†Ô∏è"
print(f"   Calidad del clustering con k={best_k_silhouette}: {calidad}")
print(f"   Score: {best_silhouette_score:.3f}")

# 7. Recomendaci√≥n final
print(f"\n" + "=" * 70)
print("üéØ RECOMENDACI√ìN FINAL PARA K")
print("=" * 70)
print(f"   M√©todo del codo sugiere: k={codo_k}")
print(f"   Silhouette sugiere: k={best_k_silhouette}")

# Decidir k √≥ptimo basado en ambos m√©todos
if abs(codo_k - best_k_silhouette) <= 1:
    k_optimo = best_k_silhouette
    print(f"   ‚úÖ Ambos m√©todos convergen: k={k_optimo} es √ìPTIMO")
else:
    k_optimo = best_k_silhouette  # Priorizamos silhouette
    print(f"   ‚öñÔ∏è  M√©todos difieren. Recomendamos k={k_optimo} (mayor silhouette)")
    print(f"      Tambi√©n considera k={codo_k} como alternativa")

# An√°lisis de distribuci√≥n de entregas en clusters
print(f"\nüì¶ DISTRIBUCI√ìN DE ENTREGAS EN CLUSTERS (k={best_k_silhouette}):")
cluster_labels_best = silhouette_results[best_k_silhouette]['cluster_labels']
for i in range(best_k_silhouette):
    count = np.sum(cluster_labels_best == i)
    pct = (count / len(cluster_labels_best)) * 100
    bar_size = int(pct / 2)
    bar = "‚ñà" * bar_size
    print(f"   Cluster {i}: {count:4d} entregas ({pct:5.1f}%) {bar}")

# 8. Guardar resultados de la evaluaci√≥n
print(f"\n" + "=" * 70)
print("GUARDANDO RESULTADOS DE EVALUACI√ìN")
print("=" * 70)

# Guardar m√©tricas de evaluaci√≥n para todos los k probados
evaluation_results = pd.DataFrame({
    'k': k_range,
    'inertia': inertias,
    'silhouette_score': [0] + silhouette_scores[1:]  # k=1 no tiene silhouette
})

# A√±adir reducci√≥n porcentual de inercia
evaluation_results['inertia_reduction_pct'] = [0] + diferencias

evaluation_results.to_csv('entregas_k_evaluation_results.csv', index=False)

print("‚úÖ Archivos generados:")
print("   - entregas_k_evaluation_results.csv: M√©tricas de evaluaci√≥n para cada k")

# Guardar informaci√≥n detallada del k √≥ptimo
with open('entregas_k_optimo_recomendacion.txt', 'w', encoding='utf-8') as f:
    f.write("=" * 70 + "\n")
    f.write("RECOMENDACI√ìN DE K √ìPTIMO - SISTEMA DE ENTREGAS LOG√çSTICAS\n")
    f.write("=" * 70 + "\n\n")
    f.write(f"K √≥ptimo recomendado: {k_optimo}\n")
    f.write(f"Silhouette Score: {best_silhouette_score:.3f}\n")
    f.write(f"Calidad del clustering: {calidad}\n\n")
    f.write(f"M√©todo del codo sugiere: k={codo_k}\n")
    f.write(f"Silhouette sugiere: k={best_k_silhouette}\n\n")
    f.write("Distribuci√≥n de entregas en clusters:\n")
    for i in range(best_k_silhouette):
        count = np.sum(cluster_labels_best == i)
        pct = (count / len(cluster_labels_best)) * 100
        f.write(f"  Cluster {i}: {count} entregas ({pct:.1f}%)\n")

print("   - entregas_k_optimo_recomendacion.txt: Recomendaci√≥n detallada")

print(f"\nüéâ EVALUACI√ìN DE K COMPLETADA")
print(f"   üìã Resultados guardados en: entregas_k_evaluation_results.csv")
print(f"   üìÑ Recomendaci√≥n guardada en: entregas_k_optimo_recomendacion.txt")
print(f"   üéØ K √≥ptimo recomendado: k={k_optimo}")
print(f"   üìä Silhouette score del k √≥ptimo: {best_silhouette_score:.3f}")
print(f"   üèÜ Calidad del clustering: {calidad}")

print(f"\n" + "=" * 70)
print("PR√ìXIMOS PASOS")
print("=" * 70)
print(f"‚úÖ Usa k={k_optimo} para entrenar tu modelo K-means final")
print("‚úÖ Los archivos CSV contienen todas las m√©tricas de evaluaci√≥n")
print("‚úÖ Puedes revisar k alternativas si necesitas m√°s/menos clusters")
print("‚úÖ Considera el contexto de negocio para la decisi√≥n final")

print(f"\nüí° INTERPRETACI√ìN DE CLUSTERS PARA EL NEGOCIO:")
print("   Los clusters pueden representar:")
print("   ‚Ä¢ Tipos de entregas con caracter√≠sticas similares")
print("   ‚Ä¢ Patrones de demora y rendimiento")
print("   ‚Ä¢ Grupos de riesgo log√≠stico")
print("   ‚Ä¢ Segmentos para optimizaci√≥n de rutas")